{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Message', 'Category']\n",
    "data = pd.read_csv(\"roman_urdu.csv\", usecols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n Un ki biwi aur waldah Iqbal ka naam Imam Bi...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nAllama Iqbal ke walid Sheikh Noor Muhammad k...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nAllama Iqbal ki waldah ka inteqal9 November ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aakhirkar is wusat-e-beyan ka intezam ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aala taleem ke liye Cambridge gae to a...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20010</th>\n",
       "      <td>üòèüòèüòèok nikal giii</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20011</th>\n",
       "      <td>üòíüòí ye joh prem katha likhi hai na upr isi ko i...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20012</th>\n",
       "      <td>üòõüòúüòúüòõ I miss u my namonayüòòüòòüòò</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20013</th>\n",
       "      <td>üòÜsame situation kuch mari b</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20014</th>\n",
       "      <td>üòÜüòÜ smjh to gae hun ge ap cup ki jgh kch r ho t...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20015 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Message Category\n",
       "0      \\n Un ki biwi aur waldah Iqbal ka naam Imam Bi...      ham\n",
       "1      \\nAllama Iqbal ke walid Sheikh Noor Muhammad k...      ham\n",
       "2      \\nAllama Iqbal ki waldah ka inteqal9 November ...      ham\n",
       "3              Aakhirkar is wusat-e-beyan ka intezam ...      ham\n",
       "4              Aala taleem ke liye Cambridge gae to a...      ham\n",
       "...                                                  ...      ...\n",
       "20010                                   üòèüòèüòèok nikal giii      ham\n",
       "20011  üòíüòí ye joh prem katha likhi hai na upr isi ko i...      ham\n",
       "20012                        üòõüòúüòúüòõ I miss u my namonayüòòüòòüòò     spam\n",
       "20013                        üòÜsame situation kuch mari b      ham\n",
       "20014  üòÜüòÜ smjh to gae hun ge ap cup ki jgh kch r ho t...      ham\n",
       "\n",
       "[20015 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(message):\n",
    "    \n",
    "# remove punctuations\n",
    "    message = [word for word in message if word not in string.punctuation]\n",
    "# join the message after removing   \n",
    "    message = ''.join(message)\n",
    "    \n",
    "    return [word for word in message.split() if word.lower() not in stopwords.words('english')]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# apply the text processing to messages column\n",
    "data['Message'].apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a vectorizer\n",
    "vectorizer = CountVectorizer().fit(data['Message'])\n",
    "vec_file = 'vectorizer_urdu'\n",
    "pickle.dump(vectorizer, open(vec_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the messages into bag of words using vectorizer\n",
    "bag_of_words_messages = vectorizer.transform(data['Message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (20015, 32205)\n",
      "Amount of Non-Zero occurences:  236097\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Sparse Matrix: ', bag_of_words_messages.shape)\n",
    "print('Amount of Non-Zero occurences: ', bag_of_words_messages.nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF for weights and normalization of vectors\n",
    "tf_transformer = TfidfTransformer().fit(bag_of_words_messages)\n",
    "vec_file = 'transformer_urdu'\n",
    "pickle.dump(tf_transformer, open(vec_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_messages = tf_transformer.transform(bag_of_words_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20015, 32205)\n"
     ]
    }
   ],
   "source": [
    "print(tf_idf_messages.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a training and testing set \n",
    "msg_train, msg_test, cat_train, cat_test = train_test_split(tf_idf_messages, data['Category'], test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting into Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classify = MultinomialNB().fit(msg_train,cat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsNB = nb_classify.predict(msg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      0.74      0.85      6004\n",
      "        spam       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.74      6005\n",
      "   macro avg       0.50      0.37      0.43      6005\n",
      "weighted avg       1.00      0.74      0.85      6005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictionsNB, cat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('naive_bayes_urdu','wb') as f:\n",
    "    pickle.dump(nb_classify,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting into Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_classify = LogisticRegression(max_iter=10000).fit(msg_train,cat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsLR = lr_classify.predict(msg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.74      0.85      5902\n",
      "        spam       0.02      0.31      0.04       103\n",
      "\n",
      "    accuracy                           0.73      6005\n",
      "   macro avg       0.50      0.53      0.44      6005\n",
      "weighted avg       0.97      0.73      0.83      6005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictionsLR, cat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('logistic_regression_urdu','wb') as f:\n",
    "    pickle.dump(lr_classify,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting into Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classify = DecisionTreeClassifier().fit(msg_train,cat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsDT = dt_classify.predict(msg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.80      0.74      0.77      4779\n",
      "        spam       0.22      0.28      0.24      1226\n",
      "\n",
      "    accuracy                           0.65      6005\n",
      "   macro avg       0.51      0.51      0.51      6005\n",
      "weighted avg       0.68      0.65      0.66      6005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictionsDT, cat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('decision_tree_urdu','wb') as f:\n",
    "    pickle.dump(dt_classify,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
